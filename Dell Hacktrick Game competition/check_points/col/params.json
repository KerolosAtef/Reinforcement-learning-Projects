{
  "callbacks": "<class 'hacktrick_rl.rllib.rllib.TrainingCallbacks'>",
  "clip_param": 0.05,
  "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x7f4ec1387ca0>",
  "eager": false,
  "entropy_coeff_schedule": [
    [
      0,
      0.1
    ],
    [
      300000.0,
      0.01
    ]
  ],
  "env_config": {
    "env_params": {
      "horizon": 500,
      "mlam_params": {
        "counter_drop": [],
        "counter_goals": [],
        "counter_pickup": [],
        "same_motion_goals": true,
        "start_orientations": false,
        "wait_allowed": false
      }
    },
    "eval_mdp_params": {
      "layout_name": "leaderboard_collaborative",
      "rew_shaping_params": {
        "CONSTRUCTION_SITE_DISTANCE_REW": 0,
        "CONTAINER_DISP_DISTANCE_REW": 0,
        "CONTAINER_PICKUP_REWARD": 6,
        "PLACEMENT_IN_CONSTRUCTION_SITE_REW": 5,
        "SOLARLAB_DISTANCE_REW": 0,
        "SOLARLAB_PICKUP_REWARD": 8
      }
    },
    "mdp_params": {
      "layout_name": "leaderboard_collaborative",
      "rew_shaping_params": {
        "CONSTRUCTION_SITE_DISTANCE_REW": 0,
        "CONTAINER_DISP_DISTANCE_REW": 0,
        "CONTAINER_PICKUP_REWARD": 6,
        "PLACEMENT_IN_CONSTRUCTION_SITE_REW": 5,
        "SOLARLAB_DISTANCE_REW": 0,
        "SOLARLAB_PICKUP_REWARD": 8
      }
    },
    "multi_agent_params": {
      "bc_schedule": [
        [
          0,
          0
        ],
        [
          Infinity,
          0
        ]
      ],
      "mode": "collaborative",
      "reward_shaping_factor": 1.0,
      "reward_shaping_horizon": 2500000.0,
      "use_phi": true
    },
    "outer_shape": null
  },
  "evaluation_interval": 50,
  "gamma": 0.99,
  "grad_clip": 0.1,
  "kl_coeff": 0.2,
  "lambda": 0.98,
  "log_level": "WARN",
  "lr": 0.001,
  "lr_schedule": null,
  "multiagent": {
    "policies": {
      "ppo": [
        null,
        "Box(0.0, inf, (7, 7, 30), float32)",
        "Discrete(6)",
        {
          "model": {
            "custom_model": "MyPPOModel",
            "custom_options": {
              "D2RL": false,
              "NUM_CONV_LAYERS": 3,
              "NUM_FILTERS": 25,
              "NUM_HIDDEN_LAYERS": 3,
              "SIZE_HIDDEN_LAYERS": 128
            }
          }
        }
      ]
    },
    "policies_to_train": "ppo",
    "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x7f4ec1387b80>"
  },
  "num_gpus": 1,
  "num_sgd_iter": 8,
  "num_workers": 0,
  "rollout_fragment_length": 400,
  "seed": 1,
  "sgd_minibatch_size": 2000,
  "train_batch_size": 12000,
  "vf_loss_coeff": 0.0001,
  "vf_share_layers": true
}